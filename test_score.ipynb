{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of the score auto-calibration procedure used by HH-Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HHsearch/HHblits tools use extreme value distribution (EVD) model for deriving hit's $P{\\text -}value$, $E{\\text -}value$, and $Probability$ estimates from query-target local alignment similarity score. Acording to EVD model $P{\\text -}value$ is a probability of false positive hit observation with the best score that is equal or higher than $score$ value:\n",
    "\n",
    "$P_{value}(score) = 1 - exp(-exp(\\lambda \\cdot (score - \\mu)))$\n",
    "\n",
    "HHsearch EVD parameters $\\lambda$ and $\\mu$ indirectly depend on the query and target lengths. Prior to HHsearch version 1.6.0, an empirical calibration of query and/or target HMM profiles was used for determining EVD $\\lambda$ and $\\mu$. This approach was justified by the statistics of scores for non-homologous sequences, which were obtained during the calibration step that was time-consuming. Starting from HHsearch version 1.6.0, $\\lambda$ and $\\mu$ an auto-calibration procedure was introduced &ndash; EVD parameters are now calculated from query and target profile lengths and diversities by two simple artificial neural networks, essentially two nonlinear functions. The parameters of these neural networks were derived by training process performed against a set of SCOP database profiles with objective to reproduce $\\lambda$ and $\\mu$ values obtained by the prior calibration procedure, see \"3.5. P-value calculation with neural networks\" section in {[Remmert, 2011](https://www.semanticscholar.org/paper/Fast%2C-sensitive-protein-sequence-searches-using-of-Remmert/393d2c27ee4db5973389ba28e2483f66a724f104)}. See HH-Suite [User Guide](https://github.com/soedinglab/hh-suite/wiki#dont-i-need-to-calibrate-my-query-or-database-hmm) for the description of this feature.\n",
    "In HH-Suite v.2.x versions there was an option, \"-calm\", that enables manual calibration for backward compatibility with older versions. However in contemporary HH-Suite v.3.x versions this option was deleted.\n",
    "\n",
    "HH-Suite auto-calibration feature was designed and tested with search queries and targets of size 80-300aa (median SCOP database item length is 142) which leaves some amount of uncertainty about its robustness outside this context.\n",
    "For instance, hits that are obtained by too short or too long queries could be unfairly upvoted or downvoted, respectively. This could result in precision decrease when $Probability$ or $E{\\text -}value$ is used as a threshold.\n",
    "\n",
    "Note also that distribution of hit scores depends on several HHsearch/HHblits options, namely `-shift [-1,1]; -corr [0,1]; -sc [01235]; -alt <int>`. Auto-calibration algorithm was trained with one set of options (undocumented?) and therefore user could get biased $E{\\text -}values$ even with medium-sized profiles when non-default option values are used.\n",
    "\n",
    "Hit $Probability$ value which has meaning of \"estimation for probability of homologous relation between regions of hit alignment\" is made with use of the hit secondary structure score (SS score).\n",
    "It's calculated as:\n",
    "\n",
    "$Probability = {(1 + t^2)}^{-1}$\n",
    "\n",
    "where\n",
    "\n",
    "$t = a \\cdot exp({- score_2 \\over b}) + c \\cdot exp({- score_2 \\over d})$\n",
    "\n",
    "and $score_2$ is a combined hit score, defined as\n",
    "\n",
    "$score_2 = {20 \\over 9} \\left( \\lambda \\cdot (score - \\mu) + min(\\lambda \\cdot score_{ss}, max(0, {score - 8 \\over 5}))\\right) + 3$\n",
    "\n",
    "with $score$ representing raw Viterbi hit score and $score_{ss}$ &ndash; hit secondary structure score.<br>\n",
    "The $a,b,c,d$ constants have two sets of values depending on the availability of secondary structure information (i.e. $score_{ss}$ value):\n",
    "\n",
    "$a = \\sqrt{6000}; b = 5; c = \\sqrt{0.12}; d = 64$\n",
    "\n",
    "when SS score is available and\n",
    "\n",
    "$a = \\sqrt{4000}; b = 5; c = \\sqrt{0.15}; d = 68$\n",
    "\n",
    "when there is no SS score.\n",
    "\n",
    "Apparently, these $a,b,c,d$ constants were tuned during benchmarking process at early stages of HHsearch development.<br>\n",
    "The actual code is a little bit more complex, it uses few computational optimizations, see the Python code below.\n",
    "\n",
    "These observations motivated us to design this notebook for revealing hidden properties of HH-Suite hit evaluation and assessing its applicability in extreme cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: Use **Shift+Enter** to execute the code cells below. The order of execution is important (top to bottom).<br>\n",
    "All the cells can be executed with **Kernel/Restart and Run all** menu command or **>>** toolbar button. When some cell is modified it should be re-executed (all the dependent cells might also need update, **Cell/Run All Below** menu command does this).<br>**Ctrl-Z** hotkey undoes cell changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import copy as cp\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "from cycler import cycler # for B/W theme\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "monochrome = (cycler('color', ['k']) * cycler('linestyle', ['-', '--', ':', '=.']) * cycler('marker', ['^',',', '.']))\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16,\n",
    "       }\n",
    "matplotlib.rc('font', **font)\n",
    "savePDF = False\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below were translated from C++ code of HH-Suite package.\n",
    "The code looks a bit messy and lack proper documentation but it's exactly the code that was introduced in version 1.6.0 and hasn't been changed much since then.\n",
    "\n",
    "Note, that the code corresponds only to local search mode of HHsearch tool (global search mode uses a bit different $Probability$ formula and HHblits tool reports $E{\\text -}value$ which is also corrected by $E{\\text -}value$ corresponding to prefiltering step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hit:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "\n",
    "def CalculatePvalues(h):\n",
    "    \"\"\"Calculates P-value, E-value, and Probability for the hit\n",
    "    using Viterbi score, SS score, and EVD lamda/mu values\n",
    "    obtained from query/template lengths and diversity values.\n",
    "    \"\"\"\n",
    "    log1000 = math.log(1000.0)\n",
    "    query_log_len = math.log(h.q_L)/log1000\n",
    "    hit_log_len = math.log(h.t_L)/log1000\n",
    "    h.lamda = lamda_NN(query_log_len, hit_log_len, h.q_Neff/10.0, h.t_Neff/10.0)\n",
    "    h.mu = mu_NN(query_log_len, hit_log_len, h.q_Neff/10.0, h.t_Neff/10.0)\n",
    "    h.logPval = logPvalue(h.score,h.lamda,h.mu)\n",
    "    h.Pval = Pvalue(h.score,h.lamda,h.mu)\n",
    "    h.Eval = math.exp(h.logPval + math.log(h.N_searched))\n",
    "    h.logEval = h.logPval + math.log(h.N_searched)\n",
    "    if h.logPval < -10.0:\n",
    "        x = h.logPval\n",
    "    else:\n",
    "        x = math.log(-math.log(1-h.Pval))\n",
    "    h.score_aass = x/0.45 - min(h.lamda*h.score_ss,max(0.0,0.2*(h.score-8.0)))/0.45 - 3.0\n",
    "    h.Probab = Probab(-h.score_aass, h.score_ss != 0.0)\n",
    "\n",
    "def calc_hidden_output(weights, bias, Lqnorm, Ltnorm, Nqnorm, Ntnorm):\n",
    "    \"Calculate output of hidden neural network units\"\n",
    "    # Calculate activation of hidden unit = sum of all inputs * weights + bias\n",
    "    res = Lqnorm*weights[0] + Ltnorm*weights[1] + Nqnorm*weights[2] + Ntnorm*weights[3] + bias\n",
    "    res = 1.0 / (1.0 + math.exp(-(res))) # logistic function\n",
    "    return res\n",
    "\n",
    "def lamda_NN(Lqnorm, Ltnorm, Nqnorm, Ntnorm):\n",
    "    \"Neural network regressions of lamda for EVD\"\n",
    "    inputs = 4\n",
    "    hidden = 4\n",
    "    biases = [-0.73195, -1.43792, -1.18839, -3.01141] # bias for all hidden units\n",
    "    weights = [ # Weights for the neural networks (column = start unit, row = end unit)\n",
    "        -0.52356, -3.37650, 1.12984, -0.46796,\n",
    "        -4.71361, 0.14166, 1.66807, 0.16383,\n",
    "        -0.94895, -1.24358, -1.20293, 0.95434,\n",
    "        -0.00318, 0.53022, -0.04914, -0.77046,\n",
    "        2.45630, 3.02905, 2.53803, 2.64379\n",
    "    ]\n",
    "    lamda=0.0\n",
    "    for h in range(hidden):\n",
    "        lamda += calc_hidden_output(weights[inputs*h:], biases[h], Lqnorm,Ltnorm,Nqnorm,Ntnorm) * weights[hidden*inputs+h]\n",
    "    return lamda\n",
    "\n",
    "def mu_NN(Lqnorm, Ltnorm, Nqnorm, Ntnorm):\n",
    "    \"Neural network regressions of mu for EVD\"\n",
    "    inputs = 4\n",
    "    hidden = 6\n",
    "    biases = [-4.25264, -3.63484, -5.86653, -4.78472, -2.76356, -2.21580]  # bias for all hidden units\n",
    "    weights = [ # Weights for the neural networks (column = start unit, row = end unit)\n",
    "        1.96172, 1.07181, -7.41256, 0.26471,\n",
    "        0.84643, 1.46777, -1.04800, -0.51425,\n",
    "        1.42697, 1.99927, 0.64647, 0.27834,\n",
    "        1.34216, 1.64064, 0.35538, -8.08311,\n",
    "        2.30046, 1.31700, -0.46435, -0.46803,\n",
    "        0.90090, -3.53067, 0.59212, 1.47503,\n",
    "        -1.26036, 1.52812, 1.58413, -1.90409, 0.92803, -0.66871\n",
    "    ]\n",
    "    mu=0.0\n",
    "    for h in range(hidden):\n",
    "        mu += calc_hidden_output(weights[inputs*h:], biases[h], Lqnorm,Ltnorm,Nqnorm,Ntnorm) * weights[hidden*inputs+h]\n",
    "    return 20.0*mu\n",
    "\n",
    "def Pvalue(x, lamda, mu):\n",
    "    h = lamda*(x-mu)\n",
    "    if h > 10:\n",
    "        return math.exp(-h)\n",
    "    else:\n",
    "        return 1.0 - math.exp(-math.exp(-h))\n",
    "\n",
    "def logPvalue(x, lamda, mu):\n",
    "    h = lamda*(x-mu)\n",
    "    if h > 10:\n",
    "        return -h\n",
    "    else:\n",
    "        if h < -2.5:\n",
    "            return -math.exp(-math.exp(-h))\n",
    "        else:\n",
    "            return math.log((1.0 - math.exp(-math.exp(-h))))\n",
    "\n",
    "def Probab(s, has_ss):\n",
    "    \"\"\"\n",
    "    Calculate probability of true positive : p_TP(score)/( p_TP(score)+p_FP(score) )\n",
    "    TP: same superfamily OR MAXSUB score >=0.1\n",
    "    \"\"\"\n",
    "    if s > 200:\n",
    "        return 100.0\n",
    "    if has_ss:\n",
    "        # local with SS\n",
    "        a=math.sqrt(6000.0)\n",
    "        b=2.0*2.5\n",
    "        c=math.sqrt(0.12)\n",
    "        d=2.0*32.0\n",
    "    else:\n",
    "        # local no SS\n",
    "        a=math.sqrt(4000.0)\n",
    "        b=2.0*2.5\n",
    "        c=math.sqrt(0.15)\n",
    "        d=2.0*34.0\n",
    "    t = a*math.exp(-s/b) + c*math.exp(-s/d)\n",
    "    return 100.0/(1.0+t*t) # ??? JS Jul'12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the set of hits taken from HHsearch output files (query and target profiles' diversity, Neff, can be found in the header of HMM file).<br>\n",
    "The Example 4.1 with precise $Score$, $P{\\text -}value$, and $Probability$ values was obtained from specially modified HHsearch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {'name': 'Example 1',\n",
    "     'file': 'YP_009179227.1-PF08301.12',\n",
    "     'comment': 'It has the highest probability gain due to large query length decrease'\n",
    "    },\n",
    "    {'name': 'Example 2',\n",
    "     'file': 'YP_009388303.1-PF13238.5',\n",
    "     'comment': 'It shows high probability gain in spite of smaller decrease of the query length (high target profile diversity, Neff=11.5)'\n",
    "    },\n",
    "    {'name': 'Example 3',\n",
    "     'file': 'YP_004070193.2-PF14519.5',\n",
    "     'comment': 'It shows low probability gain in spite of large query length decrease (it has high score, thus the Probability for iteration #1 is already high)',\n",
    "     'figure6': 'Note: Visible deviation of P-value estimation for LAMPA case is explained by score decrease (shorter query profile has different background aa frequencies, see default \"-sc 1\" option)'\n",
    "    },\n",
    "    {'name': 'Example 4',\n",
    "     'file': 'NP_690588.1-PF01728.18',\n",
    "     'comment': 'Another example with high target profile diversity (Neff=11.7)'\n",
    "    },\n",
    "    # Hits can be described explicitly here (e.g. with more precise score, ss_score, and other values,\n",
    "    # obtained from modified version of HHsearch):\n",
    "    {'name': 'Example 4.1',\n",
    "     'comment': 'High precision version of Example 4',\n",
    "     'hits': [\n",
    "        # NP_690588.1_1-2474 vs. PF01728.18 (iteration_1)\n",
    "        Hit(score=40.7270432, score_ss=-0.0733758, q_Neff=1.0, t_Neff=11.7, q_L=2474, t_L=183, N_searched=1,\n",
    "            Probab_HH=77.7733154, Pval_HH=1.50802e-05, query='NP_690588.1', query_coords='1-2474',\n",
    "            target='PF01728.18', iteration='1', comment='HHsearch'),\n",
    "        # NP_690588.1_1166-1348 vs. PF01728.18 (iteration_2)\n",
    "        Hit(score=39.3617821, score_ss=-0.0733758, q_Neff=1.0, t_Neff=11.7, q_L=(1348-1166+1), t_L=183, N_searched=1,\n",
    "            Probab_HH=95.1556091, Pval_HH=1.15029e-07, query='NP_690588.1', query_coords='1166-1348',\n",
    "            target='PF01728.18', iteration='2', comment='LAMPA')\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "hits = []\n",
    "\n",
    "def getHits(item):\n",
    "    global hits\n",
    "    if 'hits' in item:\n",
    "        hits = item['hits']\n",
    "    elif 'file' in item:\n",
    "        with open('input/' + item['file'] + '.csv') as f:\n",
    "            csv_reader = csv.reader(f)\n",
    "            hits = []\n",
    "            for r in csv_reader:\n",
    "                if r[0] == 'Query':\n",
    "                    continue\n",
    "                if r[4] == 'iteration #1':\n",
    "                    r[4] = 'HHsearch'\n",
    "                else:\n",
    "                    r[4] = 'LAMPA'\n",
    "                h = Hit(\n",
    "                    query=r[0],\n",
    "                    query_coords=r[1],\n",
    "                    target=r[2],\n",
    "                    iteration=r[3],\n",
    "                    comment=r[4],\n",
    "                    Probab_HH=float(r[5]),\n",
    "                    Pval_HH=float(r[6]),\n",
    "                    score=float(r[7]),\n",
    "                    score_ss=float(r[8]),\n",
    "                    q_L=int(r[9]),\n",
    "                    t_L=int(r[10]),\n",
    "                    q_Neff=float(r[11]),\n",
    "                    t_Neff=float(r[12]),\n",
    "                    N_searched=1,\n",
    "                   )\n",
    "                hits.append(h)\n",
    "\n",
    "def printHits(item, hits, comment='comment', short=False):\n",
    "    name = hits[0].query + '-' + hits[0].target\n",
    "    print('')\n",
    "    print(item['name'], ', ', name, sep='')\n",
    "    if comment in item:\n",
    "        print('')\n",
    "        print(item[comment])\n",
    "    if short:\n",
    "        for i, h in enumerate(hits):\n",
    "            CalculatePvalues(h)\n",
    "        return\n",
    "    print('')\n",
    "    print('')\n",
    "    for i, h in enumerate(hits):\n",
    "        CalculatePvalues(h)\n",
    "        print('')\n",
    "        if i == 0:\n",
    "            print('Iteration #1 or \"HHsearch\" hit (long query, low Probability):')\n",
    "        else:\n",
    "            print('Iteration #2 or \"LAMPA\" hit (short query, high Probability):')\n",
    "        print('')\n",
    "        print('Query length:', h.q_L)\n",
    "        print('HHsearch Probability: ', h.Probab_HH, '%', sep='')\n",
    "        print('HHsearch P-value:', h.Pval_HH)\n",
    "        print('Score:', h.score)\n",
    "        print('SS Score:', h.score_ss)\n",
    "        print('Target profile diversity, Neff:', h.t_Neff)\n",
    "        print('Calculated Probability: ', h.Probab, '%', sep='')\n",
    "        print('Calculated P-value:', h.Pval)\n",
    "        # print('Calculated score_aass:', h.score_aass)\n",
    "        # print('Calculated lamda:', h.lamda)\n",
    "        # print('Calculated mu:', h.mu)\n",
    "        print('')\n",
    "\n",
    "@interact\n",
    "def showExample(Name=[x['name'] for x in test_cases]):\n",
    "    item = next(x for x in test_cases if x['name'] == Name)\n",
    "    getHits(item)\n",
    "    printHits(item, hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-value and Probability values match which confirms that this calculation is correct (see the relative error $\\approx 10^{-6}$ for Example 4.1 where precise HHsearch score and probability are known)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-value and Probability as functions of query and target lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the working code we can model how $Probability$ and $P{\\text -} value$ would change if the same hit was found using query and target profiles of arbitrary different sizes.\n",
    "\n",
    "See the plots after two code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelLengths(X, type='query'):\n",
    "    Prob_A = X.copy()\n",
    "    Pval_A = X.copy()\n",
    "    for i, x in enumerate(X):\n",
    "        h = cp.copy(hits[0])\n",
    "        if type == 'query':\n",
    "            h.q_L = x\n",
    "        elif type == 'target':\n",
    "            h.t_L = x\n",
    "        CalculatePvalues(h)\n",
    "        Pval_A[i] = h.Pval\n",
    "        Prob_A[i] = h.Probab\n",
    "    return [Prob_A, Pval_A]\n",
    "\n",
    "def plotPvalProbByLengths(hits):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "    fs = 24\n",
    "    fst = 20\n",
    "    lg_fs = 18\n",
    "    fa = 0.5\n",
    "    ax1.set_prop_cycle(monochrome)\n",
    "    ax2.set_prop_cycle(monochrome)\n",
    "    fig.set_size_inches(7,11)\n",
    "\n",
    "    X = np.logspace(1, 5, num=41, base=10)\n",
    "    QProb, QPval = modelLengths(X, 'query')\n",
    "    TProb, TPval = modelLengths(X, 'target')\n",
    "\n",
    "    color = next(ax1._get_lines.prop_cycler)['color']\n",
    "    markers = ['D', 'o', 'x', '+']\n",
    "\n",
    "    ax1.loglog(X, QPval, marker='o', markersize=3, linestyle='', label='query', c=color)\n",
    "    ax1.loglog(X, TPval, marker='x', markersize=5, linestyle='', label='target')\n",
    "    # ax1.plot(X, [hits[0].Pval] * len(X), '-', zorder=0, label='original P-value')\n",
    "\n",
    "    for (i, h) in enumerate(hits):\n",
    "        ax1.scatter([h.q_L], [h.Pval], zorder=4, label=h.comment, marker=markers[i], c=color, s=64)\n",
    "\n",
    "    ax1.set_ylabel('P-value', size=fs)\n",
    "    ax1.tick_params(axis=\"x\", labelsize=fst)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=fst)\n",
    "    ax1.legend(loc='lower right', prop={'size': lg_fs}, labelspacing=0.2, framealpha=fa)\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlabel('L, query or target length', size=fs)\n",
    "    ax1.xaxis.set_tick_params(which='both', labelbottom=True)\n",
    "\n",
    "    color = next(ax2._get_lines.prop_cycler)['color']\n",
    "    ax2.semilogx(X, QProb, marker='o', markersize=3, linestyle='', label='query', c=color)\n",
    "    ax2.semilogx(X, TProb, marker='x', markersize=5, linestyle='', label='target')\n",
    "    # ax2.plot(X, [hits[0].Probab] * len(X), '-', zorder=0, label='original probability')\n",
    "    ax2.plot(X, [95] * len(X), '-', zorder=0, label='95% threshold') # c='red'\n",
    "\n",
    "    for (i, h) in enumerate(hits):\n",
    "        ax2.scatter([h.q_L], [h.Probab], zorder=4, label=h.comment, marker=markers[i], c=color, s=64)\n",
    "\n",
    "    ax2.set_ylabel('Probability', size=fs);\n",
    "    ax2.tick_params(axis=\"x\", labelsize=fst)\n",
    "    ax2.tick_params(axis=\"y\", labelsize=fst)\n",
    "    ax2.set_ylim(ymin=0, ymax=100)\n",
    "    ax2.legend(loc='lower left', prop={'size': lg_fs}, labelspacing=0.2, framealpha=fa)\n",
    "    ax2.grid(True)\n",
    "    # ax2.set_title('B', weight=800, size=16, loc='left')\n",
    "    pair_name = hits[0].query + '-' + hits[0].target\n",
    "    ax2.set_xlabel('L, query or target length\\n\\n' + pair_name, size=fs)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.3, right=.99, left=0.18, top=0.99, bottom=0.15)\n",
    "    pdffile = 'output/{}-{}-Figure-6.pdf'.format(hits[0].query, hits[0].target)\n",
    "    pngfile = 'output/{}-{}-Figure-6.png'.format(hits[0].query, hits[0].target)\n",
    "    if savePDF:\n",
    "        plt.savefig(pdffile, format='PDF')\n",
    "        plt.savefig(pngfile, dpi=110)\n",
    "    # print(hits[0].query, 'vs.', hits[0].target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def plotFigure6(Test=[x['name'] for x in test_cases]):\n",
    "    item = next(x for x in test_cases if x['name'] == Test)\n",
    "    getHits(item)\n",
    "    printHits(item, hits, short=True, comment='figure6')\n",
    "    plotPvalProbByLengths(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability as a function of query and target lengths and diversities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make 2D contour plot for Probability vs. query/traget profile lengths and diversities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2D(Q, T, hit, type='length'):\n",
    "    X,Y = np.meshgrid(Q, T, indexing='ij')\n",
    "    Z = X.copy()\n",
    "    h = cp.copy(hit)\n",
    "    for i, x in enumerate(Q):\n",
    "        for j, y in enumerate(T):\n",
    "            if type == 'length':\n",
    "                h.q_L = x\n",
    "                h.t_L = y\n",
    "            elif type == 'Neff':\n",
    "                h.q_Neff = x\n",
    "                h.t_Neff = y\n",
    "            CalculatePvalues(h)\n",
    "            Z[i, j] = h.Probab\n",
    "    return [X, Y, Z]\n",
    "\n",
    "\n",
    "def plotContours(hit):\n",
    "    q_len = np.logspace(1, 5, 41, base=10)\n",
    "    t_len = np.logspace(1, 5, 41, base=10)\n",
    "    X0, Y0, P0 = model2D(q_len, t_len, hit, 'length')\n",
    "\n",
    "    q_neff = np.linspace(1, 15, 43)\n",
    "    t_neff = np.linspace(1, 15, 43)\n",
    "    X, Y, P = model2D(q_neff, t_neff, hit, 'Neff')\n",
    "    fs = 24\n",
    "    fst = 16\n",
    "    lg_fs = 18\n",
    "    fa = 0.8\n",
    "    fc = 12\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    fig.set_size_inches(7,15)\n",
    "\n",
    "    ax1.set_xscale(\"log\", nonposx='clip')\n",
    "    ax1.set_yscale(\"log\", nonposy='clip')\n",
    "    ax1.set_title('Score = ' + ('%4.1f' % hit.score) + ', Query/Target $N_{eff}\\ =' + str(hit.q_Neff) + '/' + str(hit.t_Neff) + '$', size=fst)\n",
    "    ax1.set_xlabel('Query length', size=fs)\n",
    "    ax1.set_ylabel('Target length', size=fs)\n",
    "    ax1.tick_params(axis=\"x\", labelsize=fst)\n",
    "    ax1.tick_params(axis=\"y\", labelsize=fst)\n",
    "\n",
    "    levels = np.arange(0, 100, 5)\n",
    "\n",
    "    p = ax1.contour(X0, Y0, P0, levels=levels, colors='k')\n",
    "    ax1.clabel(p, levels[1::2], inline=1, fmt='%2.0f%%', fontsize=fc)\n",
    "    ax1.plot([hits[0].q_L], [hits[0].t_L], zorder=4, linestyle='', label='HHsearch', marker='D', c='black', markersize=8) # c=color\n",
    "    ax1.plot([hits[1].q_L], [hits[1].t_L], zorder=4, linestyle='', label='LAMPA', marker='o', c='black', markersize=8)\n",
    "\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(prop={'size': lg_fs}, labelspacing=0.2, framealpha=fa)\n",
    "\n",
    "    pair_name = hits[0].query + '-' + hits[0].target\n",
    "    ax2.set_title('Score = ' + ('%4.1f' % hit.score) + ', Query/Target lengths = ' + str(hit.q_L) + '/' + str(hit.t_L), size=fst)\n",
    "    ax2.set_xlabel('Query $N_{eff}$\\n\\n' + pair_name, size=fs)\n",
    "    ax2.set_ylabel('Target $N_{eff}$', size=fs)\n",
    "    ax2.tick_params(axis=\"x\", labelsize=fst)\n",
    "    ax2.tick_params(axis=\"y\", labelsize=fst)\n",
    "\n",
    "    levels = np.arange(0, 100, 5)\n",
    "    p = ax2.contour(X, Y, P, levels=levels, colors='k')\n",
    "    plt.xlim(left=0)\n",
    "    plt.xticks(range(1, 17, 2))\n",
    "    plt.yticks(range(1, 17, 2))\n",
    "    plt.ylim(bottom=0)\n",
    "    ax2.clabel(p, levels[0::1], inline=1, fmt='%2.0f%%', fontsize=fc)\n",
    "\n",
    "    ax2.plot([hit.q_Neff], [hit.t_Neff], zorder=4, linestyle='', label='HHsearch', marker='D', c='black', markersize=8) # c=color\n",
    "\n",
    "    ax2.legend(prop={'size': lg_fs}, labelspacing=0.2, framealpha=fa)\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.27, top=0.98, right=0.95, left=0.13)\n",
    "    pdffile = 'output/{}-{}-Figure-7.pdf'.format(hits[0].query, hits[0].target)\n",
    "    pngfile = 'output/{}-{}-Figure-7.png'.format(hits[0].query, hits[0].target)\n",
    "    if savePDF:\n",
    "        plt.savefig(pdffile, format='PDF')\n",
    "        plt.savefig(pngfile, dpi=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact\n",
    "def plotFigure7(Test=[x['name'] for x in test_cases]):\n",
    "    item = next(x for x in test_cases if x['name'] == Test)\n",
    "    getHits(item)\n",
    "    printHits(item, hits, short=True, comment='figure7')\n",
    "    plotContours(hits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min. query length that generates Probability = 95% for a given score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following calculations adress the concerns about up-voting of the hits for short query and target profiles.\n",
    "\n",
    "See the figure below, after two code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findQLenForProbab(score, probab, t_len=None, t_neff=None):\n",
    "    \"\"\"\n",
    "    Binary search for the query length that gives specified probability value\n",
    "    \"\"\"\n",
    "    a = 0\n",
    "    b = 1000000\n",
    "    count = 0\n",
    "    while a < b and count < 30:\n",
    "        count += 1\n",
    "        c = (a + b) / 2\n",
    "        h = cp.copy(hits[0])\n",
    "        h.score = score\n",
    "        h.score_ss = 0\n",
    "        h.q_L = c\n",
    "        if t_len is not None:\n",
    "            h.t_L = t_len\n",
    "        if t_neff is not None:\n",
    "            h.t_Neff = t_neff\n",
    "        try:\n",
    "            CalculatePvalues(h)\n",
    "        except ValueError:\n",
    "            # print(\"ValueError:\", h.q_L, h.score, h.lamda, h.mu, file=sys.stderr)\n",
    "            h.Pval = 1\n",
    "            h.logPval = 0\n",
    "            h.Probab = 0\n",
    "\n",
    "        if h.Probab > probab:\n",
    "            a = c\n",
    "        else:\n",
    "            b = c\n",
    "    return int(a + 0.5)\n",
    "    \n",
    "def testScores(Z, probab=95, t_len=None, t_neff=None):\n",
    "    for i, s in enumerate(S):\n",
    "        Z[i] = findQLenForProbab(s, probab, t_len, t_neff)\n",
    "\n",
    "# scores\n",
    "S = np.linspace(1, 100, num=100)\n",
    "QL_T132_NE6 = np.zeros(len(S), dtype=np.int)\n",
    "QL_T50_NE6 = np.zeros(len(S), dtype=np.int)\n",
    "QL_T132_NE15 = np.zeros(len(S), dtype=np.int)\n",
    "QL_T50_NE15 = np.zeros(len(S), dtype=np.int)\n",
    "\n",
    "# PfamA profile lengths: median=132, mean=176; N_eff: median=6.5, mean=6.55, min=1.0, max=15.8\n",
    "testScores(QL_T132_NE6, 95, 132, 6.5)\n",
    "testScores(QL_T50_NE6, 95, 50, 6.5)\n",
    "testScores(QL_T132_NE15, 95, 132, 15)\n",
    "testScores(QL_T50_NE15, 95, 50, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts = [\n",
    "    (0, 50),\n",
    "    (40., 50),\n",
    "    (40., 200.),\n",
    "    (0, 200.),\n",
    "    (0, 50)\n",
    "]\n",
    "\n",
    "codes = [\n",
    "    Path.MOVETO,\n",
    "    Path.LINETO,\n",
    "    Path.LINETO,\n",
    "    Path.LINETO,\n",
    "    Path.CLOSEPOLY,\n",
    "]\n",
    "\n",
    "path = Path(verts, codes)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(6.5,5.5)\n",
    "plt.plot(S, QL_T132_NE6, label='target L=132, $N_{eff}=6.5$', color='blue', marker='', linestyle='-', linewidth=2)\n",
    "plt.plot(S, QL_T50_NE6, label='target L=50,   $N_{eff}=6.5$', color='orange', marker='', linestyle='--', linewidth=2)\n",
    "plt.plot(S, QL_T132_NE15, label='target L=132, $N_{eff}=15$', color='green', marker='', linestyle='-.', linewidth=2)\n",
    "plt.plot(S, QL_T50_NE15, label='target L=50,   $N_{eff}=15$', color='red', marker='', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.xlabel('Hit score')\n",
    "plt.ylabel('Query length, L')\n",
    "\n",
    "plt.title(\"\")\n",
    "\n",
    "patch = patches.PathPatch(path, facecolor='lightgray', lw=1)\n",
    "ax.add_patch(patch)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0, 200)\n",
    "plt.xlim(0, 60)\n",
    "ax.grid(True)\n",
    "if savePDF:\n",
    "    plt.savefig('output/Figure-N5.pdf', format='PDF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows max. query length that gives Probability=95% for a given score, target length ($L$) and target sequence diversity ($N_{eff}$). Gray rectangle shows area of FP hits of min. length 50aa if max. false positive score is 40.0 (supposedly). Therefore the gray area under the lines presents possibilities for false hits with Probability > 95%. PfamA database has median profile length 132aa and diversity $N_{eff}=6.5$ (min. $N_{eff}=1.0$, max. $N_{eff}=15$). It follows that there is no gray area under the target $L=132aa$, $N_{eff}=6.5$. However, for shorter targets ($L=50aa$) and/or target profiles with higher diversity ($N_{eff}=6.5..15$) false hits with scores as low as 23.0 could be attributed with probability >95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straightforward check for the Probability=95% cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_hit = Hit(score=39.0, score_ss=0, q_Neff=1.0, t_Neff=6.5, q_L=45, t_L=132, N_searched=1)\n",
    "# test_hit = Hit(score=20.0, score_ss=0, q_Neff=1.0, t_Neff=15, q_L=25, t_L=50, N_searched=1)\n",
    "test_hit = Hit(score=23.0, score_ss=0, q_Neff=1.0, t_Neff=15, q_L=50, t_L=50, N_searched=1)\n",
    "CalculatePvalues(test_hit)\n",
    "print(test_hit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
